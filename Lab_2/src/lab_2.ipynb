{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sesi√≥n 2:** Procesamiento de Im√°genes ‚öôÔ∏èüñºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Instalaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\enriq\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (1.11.4)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ya existe el subdirectorio o el archivo ..\\output.\n",
      "Ya existe el subdirectorio o el archivo ..\\data_questions\\A.1.\n",
      "Error mientras se procesaba: ..\\data_questions\\A.1.\n"
     ]
    }
   ],
   "source": [
    "!mkdir ..\\output\n",
    "!mkdir -p ..\\data_questions\\A.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils import non_max_suppression, get_hsv_color_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado A: Segmentaci√≥n por color**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este apartado es segmentar los colores naranja y blanco de las im√°genes en la carpeta ``data``.\n",
    "\n",
    "1. **Tarea A.1**. Defina y ejecute el m√©todo para cargar im√°genes ``load_imgs()``.\n",
    "2. **Tarea A.2.** Defina los m√©todos ``show_image()`` y ``write_image()`` para visualizar y guardar im√°genes.\n",
    "3. **Tarea A.3.** Cambia el espacio de color de las im√°genes a uno donde la crominancia y la intensidad est√©n separados (HSV).\n",
    "4. **Tarea A.4.** Segmenta los colores anaranjados.\n",
    "5. **Tarea A.5.** Segmenta los colores blancos.\n",
    "6. **Tarea A.6.** Junta las m√°scaras para cada imagen (naranja + blanco) y segmenta cada una de ellas.\n",
    "7. **Tarea A.7.** Guarda las im√°genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.1:** Defina y ejecute el m√©todo para cargar im√°genes ``load_images()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filenames: List) -> List:\n",
    "    return [cv2.imread(filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Build a list containing the paths of all images in the data folder\n",
    "path = '../data/'\n",
    "imgs_path = [path + file_name for file_name in os.listdir(path)]\n",
    "imgs = load_images(imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.2**. Defina los m√©todos ``show_image()`` y ``write_image()`` para visualizar y guardar im√°genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Complete the method, use every argument\n",
    "def show_image(img: np.array, img_name: str = \"Image\"):\n",
    "    cv2.imshow(img_name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# TODO Complete the method, use every argument\n",
    "def write_image(output_folder: str, img_name: str, img: np.array):\n",
    "    img_path = os.path.join(output_folder, img_name)\n",
    "    cv2.imwrite(img_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.3:** Cambie el espacio de color de las im√°genes a uno donde la crominancia y la intensidad est√©n separados (HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Get a list with √¨mgs in HSV color space\n",
    "hsv_imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2HSV) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.4:** Segmente los colores anaranjados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define orange color range\n",
    "light_orange = (1, 190, 190)\n",
    "dark_orange = (255, 255, 255)\n",
    "\n",
    "# TODO Compute a list that contains a mask (which should segment orange colors) for every image.\n",
    "orange_masks = [cv2.inRange(hsv_img, light_orange, dark_orange) for hsv_img in hsv_imgs]\n",
    "\n",
    "# TODO Compute a list that contains the result of multiplying the original image with its orange colors mask.\n",
    "orange_segmented = [cv2.bitwise_and(img, img, mask=mask) for img, mask in zip(imgs, orange_masks)]\n",
    "\n",
    "# TODO Show an original image\n",
    "show_image(imgs[0], \"Original Image\")\n",
    "\n",
    "# TODO Show a mask\n",
    "show_image(orange_masks[0], \"Mask\")\n",
    "\n",
    "# TODO Show a segmented image\n",
    "show_image(orange_segmented[0], \"Segmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.5:** Segmente los colores blancos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para detectar el rango de blancos complete la siguiente celda y ejecutela para investigar el rango de valores necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hMin = 0 , sMin = 0, vMin = 0), (hMax = 255 , sMax = 255, vMax = 255)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO Discover white color ranges\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mget_hsv_color_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\unibersida\\tercero\\1cuatri\\vision\\vision\\Lab_2\\src\\utils.py:72\u001b[0m, in \u001b[0;36mget_hsv_color_ranges\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     67\u001b[0m wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m33\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# get current positions of all trackbars\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     hMin \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrackbarPos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHMin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     sMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m     vMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "# TODO Discover white color ranges\n",
    "get_hsv_color_ranges(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define white color range\n",
    "light_white = (0, 0, 140)\n",
    "dark_white = (255, 84, 255)\n",
    "\n",
    "# TODO Compute a list that contains a mask (which should segment orange colors) for every image.\n",
    "white_masks = [cv2.inRange(hsv_img, light_white, dark_white) for hsv_img in hsv_imgs]\n",
    "\n",
    "# TODO Compute a list that contains the result of multiplying the original image with its orange colors mask.\n",
    "white_segmented = [cv2.bitwise_and(img, img, mask=mask) for img, mask in zip(imgs, white_masks)]\n",
    "\n",
    "# TODO Show an original image\n",
    "show_image(imgs[0], \"Original Image\")\n",
    "\n",
    "# TODO Show a mask\n",
    "show_image(white_masks[0], \"Mask\")\n",
    "\n",
    "# TODO Show a segmented image\n",
    "show_image(white_segmented[0], \"Segmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.6:** Junte las m√°scaras para cada imagen (naranja + blanco) y segmente cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Join orange_masks and white_masks\n",
    "fish_masks = [cv2.bitwise_or(orange_mask, white_mask) for orange_mask, white_mask in zip(orange_masks, white_masks)]\n",
    "    \n",
    "# TODO Compute a list that contains the result of multiplying the original image with its complete mask.\n",
    "fish = [cv2.bitwise_and(img, img, mask=mask) for img, mask in zip(imgs, fish_masks)]\n",
    "\n",
    "# TODO Show an original image\n",
    "show_image(imgs[0], \"Original Image\")\n",
    "\n",
    "# TODO Show a mask\n",
    "show_image(fish_masks[0], \"Mask\")\n",
    "\n",
    "# TODO Show a segmented image\n",
    "show_image(fish[0], \"Segmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.7:** Guarde las im√°genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define your output folder and save every fish image\n",
    "output_folder = \"../output\"\n",
    "for i, fish_img in enumerate(fish):\n",
    "\twrite_image(output_folder=output_folder, img_name=f\"fish_{i}.jpg\", img=fish_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.1:** Segmente por color el escudo de su equipo deportivo favorito: descomp√≥ngalo en al menos 2 colores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework\n",
    "\n",
    "path = '../data_questions/A.1/'\n",
    "imgs_path = [path + file_name for file_name in os.listdir(path)]\n",
    "img = load_images(imgs_path)[0]\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hMin = 0 , sMin = 0, vMin = 0), (hMax = 255 , sMax = 255, vMax = 255)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_hsv_color_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\unibersida\\tercero\\1cuatri\\vision\\vision\\Lab_2\\src\\utils.py:72\u001b[0m, in \u001b[0;36mget_hsv_color_ranges\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     67\u001b[0m wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m33\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# get current positions of all trackbars\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     hMin \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrackbarPos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHMin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     sMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m     vMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "get_hsv_color_ranges(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_white = (0, 0, 241)\n",
    "dark_white = (255, 80, 255)\n",
    "\n",
    "light_red = (148, 150, 152)\n",
    "dark_red = (255, 255, 255)\n",
    "\n",
    "light_blue = (41, 30, 0)\n",
    "dark_blue = (150, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_mask = cv2.inRange(hsv_img, light_white, dark_white)\n",
    "white_segmented = cv2.bitwise_and(img, img, mask=white_mask)\n",
    "\n",
    "red_mask = cv2.inRange(hsv_img, light_red, dark_red)\n",
    "red_segmented = cv2.bitwise_and(img, img, mask=red_mask)\n",
    "\n",
    "blue_mask = cv2.inRange(hsv_img, light_blue, dark_blue)\n",
    "blue_segmented = cv2.bitwise_and(img, img, mask=blue_mask)\n",
    "\n",
    "show_image(img, \"Original Image\")\n",
    "show_image(white_mask, \"White Mask\")\n",
    "show_image(white_segmented, \"White Segmented\")\n",
    "show_image(red_mask, \"Red Mask\")\n",
    "show_image(red_segmented, \"Red Segmented\")\n",
    "show_image(blue_mask, \"Blue Mask\")\n",
    "show_image(blue_segmented, \"Blue Segmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join white, red and blue masks to segment the image\n",
    "bayern_mask = cv2.bitwise_or(white_mask, red_mask)\n",
    "bayern_mask = cv2.bitwise_or(bayern_mask, blue_mask)\n",
    "bayern = cv2.bitwise_and(img, img, mask=bayern_mask)\n",
    "\n",
    "show_image(bayern_mask, \"Bayern Mask\")\n",
    "show_image(bayern, \"Bayern Segmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentaje por color del escudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shield pixels: 633641\n",
      "Blue percentage: 23.45\n",
      "Red percentage: 35.809999999999995\n",
      "White percentage: 41.02\n"
     ]
    }
   ],
   "source": [
    "total_shield_pixels = np.sum(bayern_mask == 255)\n",
    "print(f\"Total shield pixels: {total_shield_pixels}\")\n",
    "\n",
    "blue_percentage = np.sum(blue_mask == 255) / total_shield_pixels\n",
    "red_percentage = np.sum(red_mask == 255) / total_shield_pixels\n",
    "white_percentage = np.sum(white_mask == 255) / total_shield_pixels\n",
    "\n",
    "print(f\"Blue percentage: {round(blue_percentage, 4)*100}\")\n",
    "print(f\"Red percentage: {round(red_percentage, 4)*100}\")\n",
    "print(f\"White percentage: {round(white_percentage, 4)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.2:** ¬øQu√© ocurre si carga las im√°genes con la funci√≥n ``imageio.read()`` y luego la muestra con el m√©todo ``show_image()``? ¬øA qu√© se debe este comportamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enriq\\AppData\\Local\\Temp\\ipykernel_10056\\1061355726.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return [imageio.imread(filename) for filename in filenames]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103 131  91]\n",
      "[ 91 131 103]\n"
     ]
    }
   ],
   "source": [
    "def load_images(filenames: List) -> List:\n",
    "    return [imageio.imread(filename) for filename in filenames]\n",
    "\n",
    "def load_images_2(filenames: List) -> List:\n",
    "\treturn [cv2.imread(filename) for filename in filenames] # POR DEFECTO CARGA EN BGR\n",
    "\n",
    "\n",
    "# TODO Homework: Load images\n",
    "path = '../data/'\n",
    "imgs_path = [path + file_name for file_name in os.listdir(path)]\n",
    "question_imgs1 = load_images(imgs_path)\n",
    "print(question_imgs1[0][0][0])\n",
    "\n",
    "question_imgs2 = load_images_2(imgs_path)\n",
    "print(question_imgs2[0][0][0])\n",
    "question_imgs1 = [cv2.cvtColor(img, cv2.COLOR_RGB2BGR) for img in question_imgs1]\n",
    "\n",
    "# TODO Homework: Show it\n",
    "for i, img in enumerate(question_imgs1):\n",
    "\tshow_image(img, f\"Image {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprimiendo por pantalla el mismo p√≠xel, vemos que imageio.imread carga las im√°genes en formato RGB, mientras que cv2.imread las carga en formato BGR, por lo que si mostramos las im√°genes cargadas con imageio.read utilizando un m√©todo de cv2, el valor de azul y rojo de los p√≠xeles se intercambiar√°. Para solucionar esto, se pueden transformar las im√°genes cargadas con imageio.imread con cv2.cvtColor(img, cv2.COLOR_RGB2BGR), de formato RGB a BGR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado B:** Filtro Gaussiano y Detecci√≥n de bordes: Sobel y Canny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este apartado es detectar los bordes de las im√°genes de la carpeta ``data``. Para ello, deber√° seguir los siguientes pasos:\n",
    "\n",
    "1. **Tarea B.1.** Defina el m√©todo ``gaussian_blur()`` que aplique un filtro gausiano para obtener im√°genes borrosas. Siga todas las indicaciones del enunciado.\n",
    "2. **Tarea B.2.** Aplique el m√©todo ``gaussian_blur()`` a todas las im√°genes en ``data``.\n",
    "\n",
    "\n",
    "3. **Tarea B.3.** Defina la funci√≥n ``sobel_edge_detector()`` que detecte bordes con el m√©todo Sobel. Siga todas las indicaciones del enunciado.\n",
    "4. **Tarea B.4.** Aplique el m√©todo ``sobel_edge_detector()`` a todas las im√°genes en ``data``.\n",
    "\n",
    "\n",
    "5. **Tarea B.5.** Defina la funci√≥n ``canny_edge_detector()`` que detecte bordes con el m√©todo Canny. Siga todas las indicaciones del enunciado.\n",
    "6. **Tarea B.6.** Aplique el m√©todo ``canny_edge_detector()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.1:** Defina el m√©todo ``gaussian_blur()`` que aplique un filtro gausiano para obtener im√°genes borrosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the method\n",
    "def gaussian_blur(img: np.array, sigma: float, filter_shape: List | None = None, verbose: bool = False) -> np.array:\n",
    "    # TODO If not given, compute the filter shape \n",
    "    if filter_shape == None:\n",
    "        filter_l = 8 * sigma + 1\n",
    "    else:\n",
    "        filter_l = filter_shape[0]\n",
    "    \n",
    "    # TODO Create the filter coordinates matrices\n",
    "    y, x = np.mgrid[0:filter_l, 0:filter_l]\n",
    "    \n",
    "    # TODO Define the formula that goberns the filter\n",
    "    formula = 1 / (sigma*np.sqrt(2 * np.pi)) * np.exp(-((x - filter_l//2) ** 2 + (y - filter_l // 2) ** 2) / (2 * sigma ** 2))\n",
    "    gaussian_filter = formula / np.sum(formula)\n",
    "    \n",
    "    # TODO Process the image\n",
    "    gb_img = cv2.filter2D(img, -1, gaussian_filter)\n",
    "    \n",
    "    if verbose:\n",
    "        show_image(img=gb_img, img_name=f\"Gaussian Blur: Sigma = {sigma}\")\n",
    "    \n",
    "    return gaussian_filter, gb_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.2.** Aplique el m√©todo ``gaussian_blur()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Get the gaussian blurred images using a list comprehension\n",
    "gauss_sigma = 1.4\n",
    "gb_imgs = [gaussian_blur(img, gauss_sigma, verbose=True) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.3:** Defina la funci√≥n ``sobel_edge_detector()`` que detecte bordes con el m√©todo Sobel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the method\n",
    "def sobel_edge_detector(img: np.array, filter: np.array, gauss_sigma: float, gauss_filter_shape: List | None = None, verbose: bool = False) -> np.array:\n",
    "    # TODO Transform the img to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\t\n",
    "\n",
    "    # TODO Get a blurry img to improve edge detections\n",
    "    _, blurred = gaussian_blur(img=gray_img, sigma=gauss_sigma, filter_shape=gauss_filter_shape, verbose=verbose)\n",
    "    \n",
    "    # Re-scale\n",
    "    blurred = blurred/255\n",
    "    \n",
    "    # TODO Get vertical edges\n",
    "    v_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Transform the filter to get the orthogonal edges\n",
    "    filter = filter.T\n",
    "    \n",
    "    # TODO Get horizontal edges\n",
    "    h_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Get edges\n",
    "    sobel_edges_img = np.hypot(v_edges, h_edges)\n",
    "    # Normalize\n",
    "    sobel_edges_img = (sobel_edges_img - np.min(sobel_edges_img)) / (np.max(sobel_edges_img) - np.min(sobel_edges_img))\n",
    "\n",
    "    # Get edges angle\n",
    "    theta = np.arctan2(h_edges, v_edges)\n",
    "    \n",
    "    # Visualize if needed\n",
    "    if verbose:\n",
    "        show_image(img=sobel_edges_img, img_name=\"Sobel Edges\")\n",
    "    \n",
    "    return np.squeeze(sobel_edges_img), np.squeeze(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.4.** Aplique el m√©todo ``sobel_edge_detector()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define a sigma value\n",
    "gauss_sigma = 1\n",
    "\n",
    "# TODO Define the Sobel filter\n",
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "# TODO Get the edges detected by Sobel using a list comprehension\n",
    "sobel_edges_imgs = [sobel_edge_detector(img, sobel_filter, gauss_sigma, verbose=True) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.5:** Defina la funci√≥n ``canny_edge_detector()`` que detecte bordes con el m√©todo Canny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the method\n",
    "def canny_edge_detector(img: np.array, sobel_filter: np.array, gauss_sigma: float, gauss_filter_shape: List | None = None, verbose: bool = False):\n",
    "    # TODO Call the method sobel_edge_detector()\n",
    "    sobel_edges_img, theta = sobel_edge_detector(img, sobel_filter, gauss_sigma, gauss_filter_shape, verbose)\n",
    "    \n",
    "    # TODO Use NMS to refine edges\n",
    "    canny_edges_img = non_max_suppression(sobel_edges_img, theta)\n",
    "    \n",
    "    if verbose:\n",
    "        show_image(canny_edges_img, img_name=\"Canny Edges\")\n",
    "        \n",
    "    return canny_edges_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.6.** Aplique el m√©todo ``canny_edge_detector()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define Sobel filter\n",
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "# TODO Define a sigma value for Gauss\n",
    "gauss_sigma = 2\n",
    "\n",
    "# TODO Define a Gauss filter shape\n",
    "gauss_filter_shape = None\n",
    "\n",
    "# TODO Get the edges detected by Canny using a list comprehension\n",
    "canny_edges = [canny_edge_detector(img, sobel_filter, gauss_sigma, gauss_filter_shape, verbose=True) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta B.1:** A√±ada ruido a las im√°genes de la carpeta ``data``. Compare los resultados que obtiene al aplicar su filtro Sobel con y sin filtro Gausiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework\n",
    "def add_noise(img):\n",
    "\tnoise = np.random.normal(0, 0.15, img.shape)\n",
    "\timg = img / 255\n",
    "\tnoisy_img = img + noise\n",
    "\tnoisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
    "\tnoisy_img_clipped = np.uint8(noisy_img_clipped * 255)\n",
    "\treturn noisy_img_clipped\n",
    "\n",
    "gray_imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in imgs]\n",
    "\n",
    "noisy_imgs = [add_noise(img) for img in gray_imgs]\n",
    "for i, noisy_img in enumerate(noisy_imgs):\n",
    "\tshow_image(noisy_img, f\"Noisy Image {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_edge_detector_modified(img: np.array, filter: np.array, gauss_sigma: float, gauss_filter_shape: List | None = None, verbose: bool = False, blur: bool = True) -> np.array:\n",
    "    # TODO Get a blurry img to improve edge detections\n",
    "    if blur:\n",
    "        _, blurred = gaussian_blur(img=img, sigma=gauss_sigma, filter_shape=gauss_filter_shape, verbose=verbose)\n",
    "    else:\n",
    "        blurred = img.copy()\n",
    "        \n",
    "    blurred = blurred/255\n",
    "\n",
    "    # TODO Get vertical edges\n",
    "    v_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Transform the filter to get the orthogonal edges\n",
    "    filter = filter.T\n",
    "    \n",
    "    # TODO Get horizontal edges\n",
    "    h_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Get edges\n",
    "    sobel_edges_img = np.hypot(v_edges, h_edges)\n",
    "    # Normalize\n",
    "    sobel_edges_img = (sobel_edges_img - np.min(sobel_edges_img)) / (np.max(sobel_edges_img) - np.min(sobel_edges_img))\n",
    "\n",
    "    # Get edges angle\n",
    "    theta = np.arctan2(h_edges, v_edges)\n",
    "    \n",
    "    # Visualize if needed\n",
    "    if verbose:\n",
    "        show_image(img=sobel_edges_img, img_name=\"Sobel Edges\")\n",
    "    \n",
    "    return np.squeeze(sobel_edges_img), np.squeeze(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigma = 3\n",
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_edges_imgs = [sobel_edge_detector_modified(img, sobel_filter, gauss_sigma, gauss_filter_shape=None, verbose=True) for img in noisy_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_edges_imgs = [sobel_edge_detector_modified(img, sobel_filter, gauss_sigma, verbose=True, blur=False) for img in noisy_imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los resultados empeoran para la imagen con filtro Gaussiano al haber presencia de ruido, que es dif√≠cilmente evitable del todo, sobre todo en im√°genes de baja calidad. Sin embargo, los resultados en la imagen sin filtro Gaussiano son notablemente peores al tener el gradiente siempre valores absolutos elevados, pues la diferencia de intensidad entre p√≠xeles siempre existe, incluso en las secciones homog√©neas, al a√±adir ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta B.2:** Utilice la librer√≠a ``scikit-image`` y compare el efecto de los filtros Sobel, Canny y Prewitt sobre las im√°genes de la carpeta ``data``. ¬øQu√© diferencias observa entre los filtros? ¬øPuede obtener alguna conclusi√≥n y/o patr√≥n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enriq\\AppData\\Local\\Temp\\ipykernel_10056\\1061355726.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return [imageio.imread(filename) for filename in filenames]\n"
     ]
    }
   ],
   "source": [
    "# TODO Homework\n",
    "import skimage as sk\n",
    "from skimage import filters, feature\n",
    "\n",
    "imgs = load_images(imgs_path)\n",
    "\n",
    "for i, img in enumerate(imgs):\n",
    "\tsobel_edges = filters.sobel(sk.color.rgb2gray(img))\n",
    "\tshow_image(sobel_edges, f\"Sobel Edges {i}\")\n",
    "\n",
    "\tcanny_edges = feature.canny(sk.color.rgb2gray(img))\n",
    "\tcanny_edges = canny_edges.astype(np.uint8) * 255\n",
    "\tshow_image(canny_edges, f\"Canny Edges {i}\")\n",
    "\n",
    "\tprewitt_edges = filters.prewitt(sk.color.rgb2gray(img))\n",
    "\tshow_image(prewitt_edges, f\"Prewitt Edges {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los resultados para los filtros Sobel y Prewitt son muy similares, pues estos se limitan a convolucionar la imagen con un kernel que, adem√°s, es bastante similar. En cambio, es bastante notable la diferencia con Canny, al involucrar este proceso pasos de reducci√≥n de ruido, c√°lculo de intensidad y direcci√≥n de gradientes, supresi√≥n de no-m√°ximos y umbralizaci√≥n por hist√©resis. El filtro Canny es el m√°s indicativo a la hora de determinar los bordes de la imagen sin a√±adir nada extra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado C (Opcional):** Operadores Morfol√≥gicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este partado, deber√° seguir los siguientes pasos:\n",
    "\n",
    "1. **Tarea C.1.** Defina el m√©todo ``binarize()`` para binarizar im√°genes.\n",
    "2. **Tarea C.2.** Defina el m√©todo ``custom_dilate()``.\n",
    "3. **Tarea C.3.** Defina el m√©todo ``custom_erode()``.\n",
    "4. **Pregunta C.1** Aplique los m√©todos ``custom_dilate()`` y ``custom_erode()`` a todas las im√°genes de la carpeta ``data``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.** Defina el m√©todo ``binarize()`` para binarizar im√°genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework: define the binarization method\n",
    "def binarize(img: np.array, threshold: int = 127):\n",
    "    binary_img = img.copy()\n",
    "    binary_img[binary_img < threshold] = 0\n",
    "    binary_img[binary_img >= threshold] = 255\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.** Defina el m√©todo ``custom_dilate()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework: define the dilation method\n",
    "def custom_dilate(img):\n",
    "    # TODO pad the original image so it can keep dimensions after processing\n",
    "    padded = np.pad(img, 1, mode='constant')\n",
    "    \n",
    "    # TODO get img shape\n",
    "    width = padded.shape[1]\n",
    "    height = padded.shape[0]\n",
    "    \n",
    "    # TODO Create an element with the same dimensions as the padded img\n",
    "    dilated = np.zeros((height - 2, width - 2))\n",
    "    \n",
    "    for j in range(1, height-1):\n",
    "        for i in range(1, width-1):\n",
    "            # TODO Add logic to the operation\n",
    "            neighborhood = padded[j - 1:j + 2, i - 1:i + 2]\n",
    "            \n",
    "            dilated[j - 1, i - 1] = np.max(neighborhood)\n",
    "    \n",
    "    return dilated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.3.** Defina el m√©todo ``custom_erode()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework: define the erotion method\n",
    "def custom_erode(img):\n",
    "    padded = np.pad(img, 1, mode='constant', constant_values=255)\n",
    "    \n",
    "    width = padded.shape[1]\n",
    "    height = padded.shape[0]\n",
    "    \n",
    "    eroded = np.zeros((height - 2, width - 2))\n",
    "    \n",
    "    for j in range(1, height - 1):\n",
    "        for i in range(1, width - 1):\n",
    "            neighborhood = padded[j - 1:j + 2, i - 1:i + 2]\n",
    "            \n",
    "            eroded[j - 1, i - 1] = np.min(neighborhood)\n",
    "    \n",
    "    return eroded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta C.1** Aplique los m√©todos ``custom_dilate()`` y ``custom_erode()`` a todas las im√°genes de la carpeta ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enriq\\AppData\\Local\\Temp\\ipykernel_10056\\1061355726.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return [imageio.imread(filename) for filename in filenames]\n"
     ]
    }
   ],
   "source": [
    "# TODO Homework\n",
    "\n",
    "imgs = load_images(imgs_path)\n",
    "gray_imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in imgs]\n",
    "binarized_imgs = [binarize(img) for img in gray_imgs]\n",
    "\n",
    "for i, img in enumerate(binarized_imgs):\n",
    "\tshow_image(img, f\"Binarized Image {i}\")\n",
    "\tshow_image(custom_dilate(img), f\"Dilated Image {i}\")\n",
    "\tshow_image(custom_erode(img), f\"Eroded Image {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
