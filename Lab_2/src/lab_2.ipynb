{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sesi√≥n 2:** Procesamiento de Im√°genes ‚öôÔ∏èüñºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Instalaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\enriq\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (1.11.4)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\enriq\\anaconda3\\lib\\site-packages (from scikit-image) (0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ya existe el subdirectorio o el archivo ..\\output.\n",
      "Ya existe el subdirectorio o el archivo ..\\data_questions\\A.1.\n",
      "Error mientras se procesaba: ..\\data_questions\\A.1.\n"
     ]
    }
   ],
   "source": [
    "!mkdir ..\\output\n",
    "!mkdir -p ..\\data_questions\\A.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils import non_max_suppression, get_hsv_color_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado A: Segmentaci√≥n por color**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este apartado es segmentar los colores naranja y blanco de las im√°genes en la carpeta ``data``.\n",
    "\n",
    "1. **Tarea A.1**. Defina y ejecute el m√©todo para cargar im√°genes ``load_imgs()``.\n",
    "2. **Tarea A.2.** Defina los m√©todos ``show_image()`` y ``write_image()`` para visualizar y guardar im√°genes.\n",
    "3. **Tarea A.3.** Cambia el espacio de color de las im√°genes a uno donde la crominancia y la intensidad est√©n separados (HSV).\n",
    "4. **Tarea A.4.** Segmenta los colores anaranjados.\n",
    "5. **Tarea A.5.** Segmenta los colores blancos.\n",
    "6. **Tarea A.6.** Junta las m√°scaras para cada imagen (naranja + blanco) y segmenta cada una de ellas.\n",
    "7. **Tarea A.7.** Guarda las im√°genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.1:** Defina y ejecute el m√©todo para cargar im√°genes ``load_images()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filenames: List) -> List:\n",
    "    return [cv2.imread(filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Build a list containing the paths of all images in the data folder\n",
    "path = '../data/'\n",
    "imgs_path = [path + file_name for file_name in os.listdir(path)]\n",
    "imgs = load_images(imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.2**. Defina los m√©todos ``show_image()`` y ``write_image()`` para visualizar y guardar im√°genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Complete the method, use every argument\n",
    "def show_image(img: np.array, img_name: str = \"Image\"):\n",
    "    cv2.imshow(img_name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# TODO Complete the method, use every argument\n",
    "def write_image(output_folder: str, img_name: str, img: np.array):\n",
    "    img_path = os.path.join(output_folder, img_name)\n",
    "    cv2.imwrite(img_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.3:** Cambie el espacio de color de las im√°genes a uno donde la crominancia y la intensidad est√©n separados (HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Get a list with √¨mgs in HSV color space\n",
    "hsv_imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2HSV) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.4:** Segmente los colores anaranjados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define orange color range\n",
    "light_orange = (1, 190, 190)\n",
    "dark_orange = (255, 255, 255)\n",
    "\n",
    "# TODO Compute a list that contains a mask (which should segment orange colors) for every image.\n",
    "orange_masks = [cv2.inRange(hsv_img, light_orange, dark_orange) for hsv_img in hsv_imgs]\n",
    "\n",
    "# TODO Compute a list that contains the result of multiplying the original image with its orange colors mask.\n",
    "orange_segmented = [cv2.bitwise_and(img, img, mask=mask) for img, mask in zip(imgs, orange_masks)]\n",
    "\n",
    "# TODO Show an original image\n",
    "show_image(imgs[0], \"Original Image\")\n",
    "\n",
    "# TODO Show a mask\n",
    "show_image(orange_masks[0], \"Mask\")\n",
    "\n",
    "# TODO Show a segmented image\n",
    "show_image(orange_segmented[0], \"Segmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.5:** Segmente los colores blancos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para detectar el rango de blancos complete la siguiente celda y ejecutela para investigar el rango de valores necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hMin = 0 , sMin = 0, vMin = 0), (hMax = 255 , sMax = 255, vMax = 255)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO Discover white color ranges\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mget_hsv_color_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\unibersida\\tercero\\1cuatri\\vision\\vision\\Lab_2\\src\\utils.py:72\u001b[0m, in \u001b[0;36mget_hsv_color_ranges\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     67\u001b[0m wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m33\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# get current positions of all trackbars\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     hMin \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrackbarPos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHMin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     sMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m     vMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "# TODO Discover white color ranges\n",
    "get_hsv_color_ranges(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define white color range\n",
    "light_white = (0, 0, 140)\n",
    "dark_white = (255, 84, 255)\n",
    "\n",
    "# TODO Compute a list that contains a mask (which should segment orange colors) for every image.\n",
    "white_masks = [cv2.inRange(hsv_img, light_white, dark_white) for hsv_img in hsv_imgs]\n",
    "\n",
    "# TODO Compute a list that contains the result of multiplying the original image with its orange colors mask.\n",
    "white_segmented = [cv2.bitwise_and(img, img, mask=mask) for img, mask in zip(imgs, white_masks)]\n",
    "\n",
    "# TODO Show an original image\n",
    "show_image(imgs[0], \"Original Image\")\n",
    "\n",
    "# TODO Show a mask\n",
    "show_image(white_masks[0], \"Mask\")\n",
    "\n",
    "# TODO Show a segmented image\n",
    "show_image(white_segmented[0], \"Segmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.6:** Junte las m√°scaras para cada imagen (naranja + blanco) y segmente cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Join orange_masks and white_masks\n",
    "fish_masks = [cv2.bitwise_or(orange_mask, white_mask) for orange_mask, white_mask in zip(orange_masks, white_masks)]\n",
    "    \n",
    "# TODO Compute a list that contains the result of multiplying the original image with its complete mask.\n",
    "fish = [cv2.bitwise_and(img, img, mask=mask) for img, mask in zip(imgs, fish_masks)]\n",
    "\n",
    "# TODO Show an original image\n",
    "show_image(imgs[0], \"Original Image\")\n",
    "\n",
    "# TODO Show a mask\n",
    "show_image(fish_masks[0], \"Mask\")\n",
    "\n",
    "# TODO Show a segmented image\n",
    "show_image(fish[0], \"Segmented Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.7:** Guarde las im√°genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define your output folder and save every fish image\n",
    "output_folder = \"../output\"\n",
    "for i, fish_img in enumerate(fish):\n",
    "\twrite_image(output_folder=output_folder, img_name=f\"fish_{i}.jpg\", img=fish_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.1:** Segmente por color el escudo de su equipo deportivo favorito: descomp√≥ngalo en al menos 2 colores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework\n",
    "\n",
    "path = '../data_questions/A.1/'\n",
    "imgs_path = [path + file_name for file_name in os.listdir(path)]\n",
    "img = load_images(imgs_path)[0]\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hMin = 0 , sMin = 0, vMin = 0), (hMax = 255 , sMax = 255, vMax = 255)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_hsv_color_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\unibersida\\tercero\\1cuatri\\vision\\vision\\Lab_2\\src\\utils.py:72\u001b[0m, in \u001b[0;36mget_hsv_color_ranges\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     67\u001b[0m wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m33\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# get current positions of all trackbars\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     hMin \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrackbarPos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHMin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     sMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m     vMin \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVMin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "get_hsv_color_ranges(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_white = (0, 0, 241)\n",
    "dark_white = (255, 80, 255)\n",
    "\n",
    "light_red = (148, 150, 152)\n",
    "dark_red = (255, 255, 255)\n",
    "\n",
    "light_blue = (41, 30, 0)\n",
    "dark_blue = (150, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_mask = cv2.inRange(hsv_img, light_white, dark_white)\n",
    "white_segmented = cv2.bitwise_and(img, img, mask=white_mask)\n",
    "\n",
    "red_mask = cv2.inRange(hsv_img, light_red, dark_red)\n",
    "red_segmented = cv2.bitwise_and(img, img, mask=red_mask)\n",
    "\n",
    "blue_mask = cv2.inRange(hsv_img, light_blue, dark_blue)\n",
    "blue_segmented = cv2.bitwise_and(img, img, mask=blue_mask)\n",
    "\n",
    "show_image(img, \"Original Image\")\n",
    "show_image(white_mask, \"White Mask\")\n",
    "show_image(white_segmented, \"White Segmented\")\n",
    "show_image(red_mask, \"Red Mask\")\n",
    "show_image(red_segmented, \"Red Segmented\")\n",
    "show_image(blue_mask, \"Blue Mask\")\n",
    "show_image(blue_segmented, \"Blue Segmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join white, red and blue masks to segment the image\n",
    "bayern_mask = cv2.bitwise_or(white_mask, red_mask)\n",
    "bayern_mask = cv2.bitwise_or(bayern_mask, blue_mask)\n",
    "bayern = cv2.bitwise_and(img, img, mask=bayern_mask)\n",
    "\n",
    "show_image(bayern_mask, \"Bayern Mask\")\n",
    "show_image(bayern, \"Bayern Segmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.2:** ¬øQu√© ocurre si carga las im√°genes con la funci√≥n ``imageio.read()`` y luego la muestra con el m√©todo ``show_image()``? ¬øA qu√© se debe este comportamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103 131  91]\n",
      "[ 91 131 103]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enriq\\AppData\\Local\\Temp\\ipykernel_1564\\3990706769.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return [imageio.imread(filename) for filename in filenames]\n"
     ]
    }
   ],
   "source": [
    "def load_images(filenames: List) -> List:\n",
    "    return [imageio.imread(filename) for filename in filenames]\n",
    "\n",
    "def load_images_2(filenames: List) -> List:\n",
    "\treturn [cv2.imread(filename) for filename in filenames] # POR DEFECTO CARGA EN BGR\n",
    "\n",
    "\n",
    "# TODO Homework: Load images\n",
    "path = '../data/'\n",
    "imgs_path = [path + file_name for file_name in os.listdir(path)]\n",
    "question_imgs = load_images(imgs_path)\n",
    "print(question_imgs[0][0][0])\n",
    "\n",
    "question_imgs = load_images_2(imgs_path)\n",
    "print(question_imgs[0][0][0])\n",
    "# question_imgs = [cv2.cvtColor(img, cv2.COLOR_RGB2BGR) for img in question_imgs]\n",
    "\n",
    "# TODO Homework: Show it\n",
    "# for i, img in enumerate(question_imgs):\n",
    "# \tshow_image(img, f\"Image {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado B:** Filtro Gaussiano y Detecci√≥n de bordes: Sobel y Canny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este apartado es detectar los bordes de las im√°genes de la carpeta ``data``. Para ello, deber√° seguir los siguientes pasos:\n",
    "\n",
    "1. **Tarea B.1.** Defina el m√©todo ``gaussian_blur()`` que aplique un filtro gausiano para obtener im√°genes borrosas. Siga todas las indicaciones del enunciado.\n",
    "2. **Tarea B.2.** Aplique el m√©todo ``gaussian_blur()`` a todas las im√°genes en ``data``.\n",
    "\n",
    "\n",
    "3. **Tarea B.3.** Defina la funci√≥n ``sobel_edge_detector()`` que detecte bordes con el m√©todo Sobel. Siga todas las indicaciones del enunciado.\n",
    "4. **Tarea B.4.** Aplique el m√©todo ``sobel_edge_detector()`` a todas las im√°genes en ``data``.\n",
    "\n",
    "\n",
    "5. **Tarea B.5.** Defina la funci√≥n ``canny_edge_detector()`` que detecte bordes con el m√©todo Canny. Siga todas las indicaciones del enunciado.\n",
    "6. **Tarea B.6.** Aplique el m√©todo ``canny_edge_detector()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.1:** Defina el m√©todo ``gaussian_blur()`` que aplique un filtro gausiano para obtener im√°genes borrosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the method\n",
    "def gaussian_blur(img: np.array, sigma: float, filter_shape: List | None = None, verbose: bool = False) -> np.array:\n",
    "    # TODO If not given, compute the filter shape \n",
    "    if filter_shape == None:\n",
    "        filter_l = 8 * sigma + 1\n",
    "    else:\n",
    "        filter_l = filter_shape[0]\n",
    "    \n",
    "    # TODO Create the filter coordinates matrices\n",
    "    y, x = np.mgrid[0:filter_l, 0:filter_l]\n",
    "    \n",
    "    # TODO Define the formula that goberns the filter\n",
    "    formula = 1 / (sigma*np.sqrt(2 * np.pi)) * np.exp(-((x - filter_l//2) ** 2 + (y - filter_l // 2) ** 2) / (2 * sigma ** 2))\n",
    "    gaussian_filter = formula / np.sum(formula)\n",
    "    \n",
    "    # TODO Process the image\n",
    "    gb_img = cv2.filter2D(img, -1, gaussian_filter)\n",
    "    \n",
    "    if verbose:\n",
    "        show_image(img=gb_img, img_name=f\"Gaussian Blur: Sigma = {sigma}\")\n",
    "    \n",
    "    return gaussian_filter, gb_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.2.** Aplique el m√©todo ``gaussian_blur()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Get the gaussian blurred images using a list comprehension\n",
    "gauss_sigma = 1.4\n",
    "gb_imgs = [gaussian_blur(img, gauss_sigma, verbose=True) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.3:** Defina la funci√≥n ``sobel_edge_detector()`` que detecte bordes con el m√©todo Sobel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the method\n",
    "def sobel_edge_detector(img: np.array, filter: np.array, gauss_sigma: float, gauss_filter_shape: List | None = None, verbose: bool = False) -> np.array:\n",
    "    # TODO Transform the img to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\t\n",
    "    \n",
    "    # TODO Get a blurry img to improve edge detections\n",
    "    _, blurred = gaussian_blur(img=gray_img, sigma=gauss_sigma, filter_shape=gauss_filter_shape, verbose=verbose)\n",
    "    \n",
    "    # Re-scale\n",
    "    blurred = blurred/255\n",
    "    \n",
    "    # TODO Get vertical edges\n",
    "    v_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Transform the filter to get the orthogonal edges\n",
    "    filter = filter.T\n",
    "    \n",
    "    # TODO Get horizontal edges\n",
    "    h_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Get edges\n",
    "    sobel_edges_img = np.hypot(v_edges, h_edges)\n",
    "    \n",
    "    # Get edges angle\n",
    "    theta = np.arctan2(h_edges, v_edges)\n",
    "    \n",
    "    # Visualize if needed\n",
    "    if verbose:\n",
    "        show_image(img=sobel_edges_img, img_name=\"Sobel Edges\")\n",
    "    \n",
    "    return np.squeeze(sobel_edges_img), np.squeeze(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.4.** Aplique el m√©todo ``sobel_edge_detector()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define a sigma value\n",
    "gauss_sigma = 2\n",
    "\n",
    "# TODO Define the Sobel filter\n",
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "# TODO Get the edges detected by Sobel using a list comprehension\n",
    "sobel_edges_imgs = [sobel_edge_detector(img, sobel_filter, gauss_sigma, verbose=True) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.5:** Defina la funci√≥n ``canny_edge_detector()`` que detecte bordes con el m√©todo Canny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the method\n",
    "def canny_edge_detector(img: np.array, sobel_filter: np.array, gauss_sigma: float, gauss_filter_shape: List | None = None, verbose: bool = False):\n",
    "    # TODO Call the method sobel_edge_detector()\n",
    "    sobel_edges_img, theta = sobel_edge_detector(img, sobel_filter, gauss_sigma, gauss_filter_shape, verbose)\n",
    "    \n",
    "    # TODO Use NMS to refine edges\n",
    "    canny_edges_img = non_max_suppression(sobel_edges_img, theta)\n",
    "    \n",
    "    if verbose:\n",
    "        show_image(canny_edges_img, img_name=\"Canny Edges\")\n",
    "        \n",
    "    return canny_edges_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.6.** Aplique el m√©todo ``canny_edge_detector()`` a todas las im√°genes en ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define Sobel filter\n",
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "# TODO Define a sigma value for Gauss\n",
    "gauss_sigma = 1.4\n",
    "\n",
    "# TODO Define a Gauss filter shape\n",
    "gauss_filter_shape = None\n",
    "\n",
    "# TODO Get the edges detected by Canny using a list comprehension\n",
    "canny_edges = [canny_edge_detector(img, sobel_filter, gauss_sigma, gauss_filter_shape, verbose=True) for img in imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta B.1:** A√±ada ruido a las im√°genes de la carpeta ``data``. Compare los resultados que obtiene al aplicar su filtro Sobel con y sin filtro Gausiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework\n",
    "def add_noise(img):\n",
    "\tnoise = np.random.normal(0, 0.15, img.shape)\n",
    "\timg = img / 255\n",
    "\tnoisy_img = img + noise\n",
    "\tnoisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
    "\treturn noisy_img_clipped\n",
    "\n",
    "gray_imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in imgs]\n",
    "\n",
    "noisy_imgs = [add_noise(img) for img in gray_imgs]\n",
    "for i, noisy_img in enumerate(noisy_imgs):\n",
    "\tshow_image(noisy_img, f\"Noisy Image {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_edge_detector_modified(img: np.array, filter: np.array, gauss_sigma: float, gauss_filter_shape: List | None = None, verbose: bool = False, blur: bool = True) -> np.array:\n",
    "    \n",
    "    # TODO Get a blurry img to improve edge detections\n",
    "    if blur:\n",
    "        _, blurred = gaussian_blur(img=img, sigma=gauss_sigma, filter_shape=gauss_filter_shape, verbose=verbose)\n",
    "    else:\n",
    "        blurred = img\n",
    "    \n",
    "    # TODO Get vertical edges\n",
    "    v_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Transform the filter to get the orthogonal edges\n",
    "    filter = filter.T\n",
    "    \n",
    "    # TODO Get horizontal edges\n",
    "    h_edges = cv2.filter2D(blurred, -1, filter)\n",
    "    \n",
    "    # TODO Get edges\n",
    "    sobel_edges_img = np.hypot(v_edges, h_edges)\n",
    "    \n",
    "    # Get edges angle\n",
    "    theta = np.arctan2(h_edges, v_edges)\n",
    "    \n",
    "    # Visualize if needed\n",
    "    if verbose:\n",
    "        show_image(img=sobel_edges_img, img_name=\"Sobel Edges\")\n",
    "    \n",
    "    return np.squeeze(sobel_edges_img), np.squeeze(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:/a/opencv-python/opencv-python/opencv/modules/highgui/src/precomp.hpp:155: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m gauss_sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      2\u001b[0m sobel_filter \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m----> 3\u001b[0m sobel_edges_imgs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43msobel_edge_detector_modified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msobel_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgauss_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnoisy_imgs\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m gauss_sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      2\u001b[0m sobel_filter \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m----> 3\u001b[0m sobel_edges_imgs \u001b[38;5;241m=\u001b[39m [\u001b[43msobel_edge_detector_modified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msobel_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgauss_sigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m noisy_imgs]\n",
      "Cell \u001b[1;32mIn[21], line 26\u001b[0m, in \u001b[0;36msobel_edge_detector_modified\u001b[1;34m(img, filter, gauss_sigma, gauss_filter_shape, verbose, blur)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Visualize if needed\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mshow_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msobel_edges_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSobel Edges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqueeze(sobel_edges_img), np\u001b[38;5;241m.\u001b[39msqueeze(theta)\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mshow_image\u001b[1;34m(img, img_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_image\u001b[39m(img: np\u001b[38;5;241m.\u001b[39marray, img_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:/a/opencv-python/opencv-python/opencv/modules/highgui/src/precomp.hpp:155: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n"
     ]
    }
   ],
   "source": [
    "gauss_sigma = 2\n",
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_edges_imgs = [sobel_edge_detector_modified(img, sobel_filter, gauss_sigma, verbose=True) for img in noisy_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigma = 2\n",
    "sobel_filter = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_edges_imgs = [sobel_edge_detector_modified(img, sobel_filter, gauss_sigma, verbose=True, blur=False) for img in noisy_imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta B.2:** Utilice la librer√≠a ``scikit-image`` y compare el efecto de los filtros Sobel, Canny y Prewitt sobre las im√°genes de la carpeta ``data``. ¬øQu√© diferencias observa entre los filtros? ¬øPuede obtener alguna conclusi√≥n y/o patr√≥n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado C (Opcional):** Operadores Morfol√≥gicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este partado, deber√° seguir los siguientes pasos:\n",
    "\n",
    "1. **Tarea C.1.** Defina el m√©todo ``binarize()`` para binarizar im√°genes.\n",
    "2. **Tarea C.2.** Defina el m√©todo ``custom_dilate()``.\n",
    "3. **Tarea C.3.** Defina el m√©todo ``custom_erode()``.\n",
    "4. **Pregunta C.1** Aplique los m√©todos ``custom_dilate()`` y ``custom_erode()`` a todas las im√°genes de la carpeta ``data``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.** Defina el m√©todo ``binarize()`` para binarizar im√°genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework: define the binarization method\n",
    "def binarize(img: np.array, threshold: int = 127):\n",
    "    binary_img = None\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.** Defina el m√©todo ``custom_dilate()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework: define the dilation method\n",
    "def custom_dilate(img):\n",
    "    # TODO pad the original image so it can keep dimensions after processing\n",
    "    padded = np.pad()\n",
    "    \n",
    "    # TODO get img shape\n",
    "    width = None\n",
    "    height = None\n",
    "    \n",
    "    # TODO Create an element with the same dimensions as the padded img\n",
    "    dilated = np.zeros()\n",
    "    \n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            # TODO Add logic to the operation\n",
    "            pass\n",
    "            \n",
    "    # TODO Select the region of interest (ROI). Modify if needed\n",
    "    dilated = dilated[1:height+1, 1:width+1]\n",
    "    \n",
    "    return dilated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.3.** Defina el m√©todo ``custom_erode()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework: define the erotion method\n",
    "def custom_erode(img):\n",
    "    eroded = None\n",
    "    \n",
    "    return eroded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta C.1** Aplique los m√©todos ``custom_dilate()`` y ``custom_erode()`` a todas las im√°genes de la carpeta ``data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
