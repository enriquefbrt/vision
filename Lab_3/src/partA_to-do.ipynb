{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sesi√≥n 3: Procesamiento Avanzado de Im√°genes** ‚öôÔ∏èüñºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado A: Detecci√≥n de esquinas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este apartado es detectar las esquinas presentes en las im√°genes de la carpeta ``data/source``.\n",
    "\n",
    "1. **Tarea A.1**. Cree una nueva capeta llamada ``partA``, dentro de la carpeta  ``data``, con el objetivo de presentar en ella los resultados de esta parte de la pr√°ctica.\n",
    "2. **Tarea A.2**. Defina y ejecute los dos m√©todos propuestos para cargar im√°genes ``imageio_load_images()`` y ``opencv_load_images()``. Observe lo que ocurre al guardar ambas im√°genes usando la misma funci√≥n ``cv2.imwrite()``.\n",
    "3. **Tarea A.3.** Defina la funci√≥n ``harris_corner_detector()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo. \n",
    "4. **Tarea A.4.** Aplique la funci√≥n ``harris_corner_detector()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios.\n",
    "5. **Tarea A.5.** Defina la funci√≥n ``shi_tomasi_corner_detection()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo.\n",
    "6. **Tarea A.6.** Aplique la funci√≥n ``shi_tomasi_corner_detection()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.1**. Cree una nueva capeta llamada ``partA``, dentro de la carpeta  ``data``, con el objetivo de presentar en ella los resultados de esta parte de la pr√°ctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO Create a folder to save all partA results (inside data)\n",
    "folder_name = \"partA\"\n",
    "folder_path = os.path.join()\n",
    "os.makedirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.2**. Defina y ejecute los dos m√©todos propuestos para cargar im√°genes ``imageio_load_images()`` y ``opencv_load_images()``. Observe lo que ocurre al guardar ambas im√°genes usando la misma funci√≥n ``cv2.imwrite()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initial part is to highlight that cv2.imshow() and cv2.imwrite() works well with previous BGR conversion\n",
    "def imageio_load_images(filenames: List) -> List:\n",
    "    '''\n",
    "    Load images using imageio.imread function (RGB)\n",
    "    '''\n",
    "    return [imageio.v2.imread(filename) for filename in filenames]\n",
    "\n",
    "def opencv_load_images(filenames: List) -> List:\n",
    "    '''\n",
    "    Load images cv2.imread function (BGR)\n",
    "    '''\n",
    "    return [cv2.imread(filename) for filename in filenames]\n",
    "\n",
    "# TODO Create two sorted lists with the paths of all images in the data/source folder using glob\n",
    "source_paths = []\n",
    "imageio_images = imageio_load_images(source_paths)\n",
    "opencv_images = opencv_load_images(source_paths)\n",
    "\n",
    "# TODO Last element of both image lists is a blue tennis court, so try saving them in partA folder\n",
    "cv2.imwrite()\n",
    "cv2.imwrite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.3.** Defina la funci√≥n ``harris_corner_detector()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define Harris Corner detection function\n",
    "def harris_corner_detector(image: np.array, blockSize: int, ksize: int, k: float):\n",
    "    '''\n",
    "    image - Input image \n",
    "    blockSize - Size of neighborhood considered for corner detection\n",
    "    ksize - Aperture parameter of the Sobel derivative used\n",
    "    k - Harris detector free parameter in the equation.\n",
    "    '''\n",
    "    # TODO Input image to Harris corner detector should be grayscale \n",
    "    gray = cv2.cvtColor()\n",
    "    # TODO Input image to Harris corner detector should be float32 type\n",
    "    gray = None\n",
    "    # TODO Apply Harris corner detection\n",
    "    harris = cv2.cornerHarris()\n",
    "    # Result is dilated for marking the corners, not important\n",
    "    harris = cv2.dilate(harris, None)\n",
    "    # TODO Threshold for an optimal value of 1% of maximal R value\n",
    "    # If pixel value > 1% max value, yo should to hightlight this as a red corner\n",
    "    image[] = [None, None, None]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.4.** Aplique la funci√≥n ``harris_corner_detector()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is designed to to change corner detection parameters for each image\n",
    "# We want to save processed image in path: Lab3/data/partA/Harris_{save_name}.jpg\n",
    "\n",
    "# First image\n",
    "save_name = \"geometry\"\n",
    "# TODO Copy first original image\n",
    "image = None\n",
    "# TODO Apply Harris Corner Detection\n",
    "harris_image = harris_corner_detector(image, blockSize = None, ksize = None, k = None)\n",
    "# TODO Save final image in partA folder\n",
    "cv2.imwrite()\n",
    "\n",
    "# Second image\n",
    "save_name = \"football\"\n",
    "# TODO Copy second original image\n",
    "image = None\n",
    "# TODO Apply Harris Corner Detection\n",
    "harris_image = harris_corner_detector(image, blockSize = None, ksize = None, k = None)\n",
    "# TODO Save final image in partA folder\n",
    "cv2.imwrite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.5.** Defina la funci√≥n ``shi_tomasi_corner_detection()``, que servir√° para la posterior aplicaci√≥n sobre las im√°genes de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO Define Shi-Tomasi corner detection function\n",
    "def shi_tomasi_corner_detection(image: np.array, maxCorners: int, qualityLevel:float, minDistance: int, corner_color: tuple, radius: int):\n",
    "    '''\n",
    "    image - Input image\n",
    "    maxCorners - Maximum number of corners to return. \n",
    "                 If there are more corners than are found, the strongest of them is returned. \n",
    "                 maxCorners <= 0 implies that no limit on the maximum is set and all detected corners are returned\n",
    "    qualityLevel - Parameter characterizing the minimal accepted quality of image corners. \n",
    "                   The parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue or the Harris function response. \n",
    "                   The corners with the quality measure less than the product are rejected. \n",
    "                   For example, if the best corner has the quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure less than 15 are rejected\n",
    "    minDistance - Minimum possible Euclidean distance between the returned corners\n",
    "    corner_color - Desired color to highlight corners in the original image\n",
    "    radius - Desired radius (pixels) of the circle\n",
    "    '''\n",
    "    # TODO Input image to Tomasi corner detector should be grayscale \n",
    "    gray = cv2.cvtColor()\n",
    "    # TODO Apply cv2.goodFeaturesToTrack function\n",
    "    corners = cv2.goodFeaturesToTrack()\n",
    "    # TODO Corner coordinates conversion to integers\n",
    "    corners = None\n",
    "    for corner in corners:\n",
    "        # Multidimensional array into flattened array, if necessary\n",
    "        x, y = corner.ravel()\n",
    "        # TODO Circle corners\n",
    "        cv2.circle()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.6.** Aplique la funci√≥n ``shi_tomasi_corner_detection()`` sobre las im√°genes de trabajo. Aseg√∫rese de que las im√°genes quedan guardadas como se especifica en los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is designed to to change corner detection parameters for each image\n",
    "# We want to save processed image in path: Lab3/data/partA/Shi-Tomasi_{save_name}.jpg\n",
    "\n",
    "# First image - Purple corners and radius = 4\n",
    "save_name = \"geometry\"\n",
    "# TODO Purple color in adequate color space\n",
    "purple_color = (None, None, None)\n",
    "# TODO Copy first original image\n",
    "image = None\n",
    "# TODO Apply Shi-Tomasi corner detection\n",
    "tomasi_image = shi_tomasi_corner_detection(image, maxCorners = None, qualityLevel = None, minDistance = None, corner_color = purple_color, radius = None)\n",
    "# TODO Save final image in partA folder\n",
    "cv2.imwrite()\n",
    "\n",
    "# Second image - Orange corners and radius = 4\n",
    "save_name = \"football\"\n",
    "# TODO Orange color in adequate color space\n",
    "orange_color = (None, None, None)\n",
    "# TODO Copy second original image\n",
    "image = None\n",
    "tomasi_image = shi_tomasi_corner_detection(image, maxCorners = None, qualityLevel = None, minDistance = None, corner_color = orange_color, radius = None)\n",
    "# TODO Save final image in partA folder\n",
    "cv2.imwrite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.1:** Realice la detecci√≥n de esquinas en las otras dos im√°genes de la carpeta ``data/source`` (cuyos nombres de guardado han de ser \"sudoku\" y \"tennis\") con el m√©todo de Harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code by yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.2:** Realice la detecci√≥n de esquinas en las otras dos im√°genes de la carpeta ``data/source`` (cuyos nombres de guardado han de ser \"sudoku\" y \"tennis\") con el m√©todo de Shi-Tomasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code by yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual Environment Lesson 3",
   "language": "python",
   "name": "3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
