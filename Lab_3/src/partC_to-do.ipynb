{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sesi√≥n 3: Procesamiento Avanzado de Im√°genes** ‚öôÔ∏èüñºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Instalaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm scikit-learn openpyxl pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "from bow import BoW\n",
    "from dataset import Dataset\n",
    "from image_classifier import ImageClassifier\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Apartado C**: Detecci√≥n de puntos de inter√©s y Bolsa de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C1: Detecci√≥n de puntos de inter√©s**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.1**: Generar funci√≥n de filtro gaussiano\n",
    "\n",
    "Se generar√° a partir de la imagen base las im√°genes con el filtrado gaussiano. Para ello se emplear√° la funci√≥n `generateGaussianImages()` que tiene que desarrollar empleando la funci√≥n [`cv2.GaussianBlur()`](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gae8bdcd9154ed5ca3cbc1766d960f45c1). Es recomendble visualizar los resultados para comprobar el funcionamiento. Para ello convierta los datos de la imagen a visualizar a `np.uint8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGaussianImages(image, sigmas):\n",
    "    \"\"\"Generate the gaussian images using the base image and the sigmas given\n",
    "\n",
    "    Args:\n",
    "        image (np.array[np.float32]): Base image to blur\n",
    "        sigmas (List[np.float32]): Sigmas for blurring the image \n",
    "\n",
    "    Returns:\n",
    "        List[np.array[np.float32]: List of blurred images\n",
    "    \"\"\"\n",
    "    gaussian_images = []\n",
    "\n",
    "    # TODO: Generate the list of blurred images using cv2.GaussianBlur()\n",
    "    image = cv2.GaussianBlur()\n",
    "    gaussian_images.append(image)\n",
    "    \n",
    "    return gaussian_images\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.2**: Generaci√≥n de espacio de escalas con im√°genes gaussianas\n",
    "\n",
    "Empleando la funci√≥n anterior, complete la siguiente celda para generar las im√°genes gaussianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Load the image in grayscale\n",
    "image = cv2.imread()\n",
    "image = image.astype(np.float32)\n",
    "# Number of diference of gaussians to generate (minimum 3)\n",
    "# TODO: Adjust this number to make sure keypoints are generated\n",
    "intervals = 3\n",
    "# Initial sigma\n",
    "sigma = 1.6 \n",
    "# We get the necessary sigmas from the given method generateGaussianSigmas()\n",
    "sigmas = generateGaussianSigmas(sigma, intervals)\n",
    "#TODO: Generate the gaussian images\n",
    "gaussian_images = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.3**: Generaci√≥n de diferencias de gaussianas\n",
    "\n",
    "Utilizando la lista de im√°genes gaussianas se generar√° una lista con las diferencias entre pares consegutivos. Para ello se emplear√° la funci√≥n `generateDoGImages()` que tiene que desarrollar empleando la funci√≥n [`cv2.subtract()`](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#gaa0f00d98b4b5edeaeb7b8333b2de353b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDoGImages(gaussian_images):\n",
    "    \"\"\"Generate Difference-of-Gaussians list\n",
    "\n",
    "    Args:\n",
    "        gaussian_images (List[np.array[np.float32]): List of blurred images\n",
    "\n",
    "    Returns:\n",
    "        List[np.array[np.float32]: List of difference of gaussian images\n",
    "    \"\"\"\n",
    "    dog_images = []\n",
    "\n",
    "    # TODO: Generate the list of difference of gaussians using cv2.subtract()\n",
    "    dog_img = cv2.subtract()\n",
    "    dog_images.append(dog_img) \n",
    "    \n",
    "    return dog_images\n",
    "\n",
    "dog_images = generateDoGImages(gaussian_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.4**: Evaluaci√≥n de extremos\n",
    "\n",
    "La funci√≥n `isPixelAnExtremum()` debe evaluar si el pixel central del bloque compuesto por las regiones de las 3 im√°genes es un m√°ximo o m√≠nimo entre ellos. Como prevenci√≥n, tenga en cuenta que puede tomar valores positivos y negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPixelAnExtremum(first_subimage, second_subimage, third_subimage, threshold):\n",
    "    \"\"\"Return True if the center element of the 3x3x3 array composed of subimages is strictly greater than or less than all its neighbors, False otherwise\n",
    "\n",
    "    Args:\n",
    "        first_subimage (np.array): Patch from first gaussian\n",
    "        second_subimage (np.array): Patch from second gaussian\n",
    "        third_subimage (np.array): Patch from third gaussian\n",
    "        threshold (float): Value threshold for the pixel\n",
    "\n",
    "    Returns:\n",
    "        Bool: True if maximum or minimum, False otherwise\n",
    "    \"\"\"\n",
    "    extremum = False\n",
    "    # TODO: Check if the center pixel value is a maximum or a minimum and if its absolute value is higher than the threshold\n",
    "\n",
    "    return extremum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_subimage = np.zeros((3,3),np.float32)\n",
    "third_subimage = np.zeros((3,3),np.float32)\n",
    "second_subimage = np.ones((3,3),np.float32)\n",
    "isPixelAnExtremum(first_subimage,second_subimage, third_subimage, 0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.5**: Localizaci√≥n de puntos clave y orientaci√≥n de los mismos\n",
    "\n",
    "La funci√≥n `findScaleSpaceExtrema()` obtendr√° los puntos clave y su orientaci√≥n a partir de las gaussianas y sus diferencias empleando, entre otras, la funci√≥n `isPixelAnExtremum()`. Deber√° completar las partes indicadas para recorrer todos los trios de im√°genes consecutivos y evaluar los p√≠xeles necesarios de estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, threshold=0.03):\n",
    "    \"\"\"Find pixel positions of all scale-space extrema in the image pyramid \"\"\"\n",
    "    keypoints = []\n",
    "\n",
    "    # TODO: Fill the loop source data\n",
    "    for image_index, (first_image, second_image, third_image) in [] :\n",
    "        # (i, j) is the center of the 3x3 array\n",
    "        # TODO: Fill the 2 range limits knowing you have to move the 3x3 window across the whole image\n",
    "        for i in range(0,0):\n",
    "            for j in range(0, 0):\n",
    "                # TODO: Fill the method with the required arguments\n",
    "                if isPixelAnExtremum():\n",
    "                    # Refine the keypoint localization\n",
    "                    localization_result = localizeExtremumViaQuadraticFit(i, j, image_index + 1, num_intervals, dog_images, sigma)\n",
    "                    if localization_result is not None:\n",
    "                        keypoint, localized_image_index = localization_result\n",
    "                        # Get the keypoint orientation\n",
    "                        keypoints_with_orientations = computeKeypointsWithOrientations(keypoint, gaussian_images[localized_image_index])\n",
    "                        for keypoint_with_orientation in keypoints_with_orientations:\n",
    "                            keypoints.append(keypoint_with_orientation)\n",
    "    return keypoints\n",
    "\n",
    "# Keypoint Detection with Taylor Expansion and Contrast Thresholding\n",
    "threshold = 0.03\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, intervals, sigma, threshold)\n",
    "visualizeKp(image, keypoints)\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "visualizeKp(image, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los puntos clave totalmente definidos y las im√°genes gaussianas ya podemos obtener los descriptores con la funci√≥n proporcionada de `generateDescriptors()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = generateDescriptors(keypoints, gaussian_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.6**: Pipeline de generaci√≥n de puntos clave y descriptores\n",
    "\n",
    "Complete la funci√≥n con los m√©todos desarrollados en tareas previas para generar los puntos clave y descriptores necesarios dada una imagen, un valor de sigma y un n√∫mero de diferencias de gaussianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeKeypointsAndDescriptors(image, sigma=1.6, num_intervals=3):\n",
    "    \"\"\"Compute SIFT keypoints and descriptors for an input image \"\"\"\n",
    "    # TODO: Fill the pipeline to get the keypoint and descriptors as before\n",
    "    image = image.astype('float32')\n",
    "    gaussian_kernels = None\n",
    "    gaussian_images = None\n",
    "    dog_images = None\n",
    "    keypoints = None\n",
    "    descriptors = None\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.1.7**: Correspondencia de caracter√≠sticas entre im√°genes\n",
    "\n",
    "Cargue las im√°genes con `cv2` y complete la llamada a la funci√≥n previa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the images with cv2 in grayscale\n",
    "img1 = None\n",
    "img2 = None\n",
    "\n",
    "# TODO: Fill the function calls\n",
    "kp1, des1 = computeKeypointsAndDescriptors()\n",
    "kp2, des2 = computeKeypointsAndDescriptors()\n",
    "\n",
    "matchFeatures(img1, kp1, des1, img2, kp2, des2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ampliaci√≥n**: SIFT con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_0 = cv2.imread('../data/0.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "image_1 = cv2.imread('../data/0_rot.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Create a SIFT detector object\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_0, descriptors_0 = sift.detectAndCompute(image_0, None)\n",
    "keypoints_1, descriptors_1 = sift.detectAndCompute(image_1, None)\n",
    "\n",
    "# Draw keypoints on the image\n",
    "image_with_keypoints_0 = cv2.drawKeypoints(image_0, keypoints_0, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "image_with_keypoints_1 = cv2.drawKeypoints(image_1, keypoints_1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "plt.imshow(image_with_keypoints_0)\n",
    "plt.title('Keypoints with Blob Sizes and Orientations')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(image_with_keypoints_1)\n",
    "plt.title('Keypoints with Blob Sizes and Orientations')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Initialize BFMatcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "\n",
    "# Perform KNN matching with k=2 for ratio test\n",
    "matches = bf.match(descriptors_0, descriptors_1)\n",
    "\n",
    "# sort matches by distance\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "\n",
    "# Draw the good matches\n",
    "matched_image = cv2.drawMatches(image_0, keypoints_0, image_1, keypoints_1, matches[:50], None,\n",
    "                                flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display the matched features\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(matched_image)\n",
    "plt.title(\"Feature Matches\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta C1**: Correspodencia de im√°genes propias y evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C2: Bolsa de palabras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.1**: Carga de los datasets de entrenamiento y validaci√≥n para la bolsa de palabras\n",
    "\n",
    "Empleando el m√©todo `load()` de la clase [`Dataset`](.\\dataset.py) que se le proporciona, cargue los datasets de entrenamiento y validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset.load()\n",
    "validation_set = Dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.2**: Extracci√≥n de los descriptores\n",
    "\n",
    "Para poder crear la bolsa de palabras se va a comenzar obteniendo los descriptores que ser√°n agrupados en las distintas palabras de nuestra bolsa. Para ello complete la carga de la imagen en la ruta `path` en escala de grises y obtenga sus descriptores con los m√©todos apropiados de cv2. Los descriptores obtenidos se a√±adir√°n a nuestra bolsa de palabras (`words`) para despu√©s ser agrupados por palabras que representen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = cv2.SIFT_create()\n",
    "\n",
    "# Extract features\n",
    "print(\"\\nComputing SIFT descriptors...\")\n",
    "time.sleep(0.1)  # Prevents a race condition between tqdm and print statements.\n",
    "descriptors = []\n",
    "for path in tqdm(training_set, unit=\"image\", file=sys.stdout):\n",
    "    # TODO: Load the image from the path in grayscale\n",
    "    image = cv2.imread()\n",
    "    try:\n",
    "        # TODO: Using the cv2 methods get the descriptors for the image\n",
    "        _, descriptor = None\n",
    "    except:\n",
    "        print(f\"WARN: Issue generating descriptor for image {path}\")\n",
    "\n",
    "    if descriptor is not None:\n",
    "        descriptors.append(descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.3**: Creaci√≥n del vocabulario\n",
    "\n",
    "A√±ada los descriptores a la bolsa (`words`) con el m√©todo add de la misma. Con los descriptores en la bolsa, se va a realizar el agrupamiento de los mismos por palabras para obtener un vocabulario de palabras visuales. Complete la ruta de apertura del archivo y establezca el modo de apertura en escrituria y bineario para poder guardar el vocabulario generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocabulary_size = 100\n",
    "iterations = 20\n",
    "termination_criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, iterations, 1e-6)\n",
    "words = cv2.BOWKMeansTrainer(vocabulary_size, termination_criteria)\n",
    "\n",
    "# TODO: Add all descriptors\n",
    "words.add()\n",
    "\n",
    "time.sleep(0.1)  # Prevents a race condition between tqdm and print statements.\n",
    "print(\"\\nClustering descriptors into\", vocabulary_size, \"words using K-means...\")\n",
    "vocabulary = words.cluster()\n",
    "filename=  \"vocabulary.pickle\"\n",
    "# TODO: Open the file from above in the write and binay mode\n",
    "with open() as f:\n",
    "    pickle.dump([\"SIFT\", vocabulary], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.4**: Entrenamiento del clasificador\n",
    "\n",
    "Una vez se tiene el vocabulario de palabras visuales, se va a entrenar al classificador. Para ello haga uso de la clase [BoW](./bow.py) y complete los m√©todos que se le indican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = BoW()\n",
    "# TODO: Especify the args for the loading method\n",
    "bow.load_vocabulary()\n",
    "\n",
    "image_classifier = ImageClassifier(bow)\n",
    "# TODO: Especify the args for the training method\n",
    "image_classifier.train()\n",
    "classifier = \"classifier\"\n",
    "image_classifier.save(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.5**: Inferencia en dataset de entrenamiento\n",
    "Con el modelo entrenado se procede a comprobar su desempe√±o con el dataset de entrenamiento. Complete los m√©todos indicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = BoW()\n",
    "# TODO: Especify the args for the loading method\n",
    "bow.load_vocabulary()\n",
    "\n",
    "image_classifier = ImageClassifier(bow)\n",
    "# TODO: Especify the args for the loading method\n",
    "image_classifier.load()\n",
    "# TODO: Especify the args for the loading method\n",
    "image_classifier.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea C.2.6**: Inferencia en dataset de evaluaci√≥n\n",
    "\n",
    "A continuaci√≥n se evalua el desempe√±o del modelo con el dataset de validaci√≥n. Complete los m√©todos indicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = BoW()\n",
    "# TODO: Especify the args for the loading method\n",
    "bow.load_vocabulary()\n",
    "\n",
    "image_classifier = ImageClassifier(bow)\n",
    "# TODO: Especify the args for the loading method\n",
    "image_classifier.load()\n",
    "# TODO: Especify the args for the loading method\n",
    "image_classifier.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta C.2.A**: Cambio de SIFT por Kaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta C.2.B**: ¬øCu√°ntas palabras uso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EXTRA - Pregunta C.2.C**: Buscando los mej√≥res par√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Homework"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
